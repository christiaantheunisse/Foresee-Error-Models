{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal error rate fit GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the data\n",
    "\n",
    "From the `dependencies` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies_folder = pathlib.Path().resolve().parent.joinpath(\"dependencies\")\n",
    "\n",
    "VelAcc = pd.read_csv(dependencies_folder.joinpath(\"VelAcc.csv\"))\n",
    "\n",
    "x_data = np.vstack((VelAcc[\"accelerations\"].to_numpy(), VelAcc[\"velocities\"].to_numpy())).T\n",
    "y_data = VelAcc[\"long_dt_errors\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit the GP on VelAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Ignore the GPU\n",
    "\n",
    "### Import the `lib` directory\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "repo_directory = pathlib.Path().resolve().parents[1]\n",
    "lib_module_dir = str(repo_directory.joinpath(\"lib\"))\n",
    "if lib_module_dir not in sys.path:\n",
    "    sys.path.insert(0, str(repo_directory.joinpath(\"lib\")))\n",
    "\n",
    "from dual_gp_model_SVGP import DualGaussianProcessWrapper, make_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS: int = 500  # 2000\n",
    "INDUCING_POINTS: int = 10\n",
    "GRID_SIZE: int = 1000\n",
    "MODEL_INFO: dict[str, str] = {\"error\": \"longitudinal error rate\", \"param1\": \"acceleration\", \"param2\": \"velocity\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the model\n",
    "\n",
    "GP_model_main = DualGaussianProcessWrapper(\n",
    "    x_data=x_data,\n",
    "    y_data=y_data,\n",
    "    train_mask=make_train_test_split(len(y_data)),\n",
    "    no_inducing_points=INDUCING_POINTS,\n",
    "    data_directory=str(pathlib.Path().resolve()),  # current directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Going to train for {EPOCHS} epochs...\")\n",
    "GP_model_main.train(epochs=EPOCHS)\n",
    "print(f\"Plotting the posterior...\")\n",
    "GP_model_main.plot_posterior()\n",
    "print(f\"Generating the error model (interpolation grid)...\")\n",
    "GP_model_main.generate_error_model(grid_size=GRID_SIZE, model_info=MODEL_INFO)\n",
    "print(f\"Saving the error model...\")\n",
    "GP_model_main.save_error_model()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the GP picture\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "fig = GP_model_main.plot_posterior(return_fig=True)\n",
    "ax1, ax2, cbar = fig.get_axes()\n",
    "ax2.remove()\n",
    "cbar.remove()\n",
    "ax1.set_xlabel(\"acceleration [m/s\" + r\"$^{2}$\" + \"]\")\n",
    "ax1.set_ylabel(\"velocity [m/s]\")\n",
    "ax1.set_zlabel(\"error [m/s]\")\n",
    "\n",
    "fig.suptitle(\"\")\n",
    "ax1.set_title(\"GP longitudinal trajectory following error rate\")\n",
    "\n",
    "ax1.set_box_aspect(aspect=None, zoom=0.88)\n",
    "\n",
    "# ax1.legend([ax1.get_children()[1], ax1.get_children()[2]], [\"mean\", \"variance\"])\n",
    "\n",
    "steps = 4\n",
    "viridis_cm = mpl.cm.get_cmap(\"viridis\")\n",
    "colourmap_handle = []\n",
    "for i in range(steps):\n",
    "    colourmap_handle.append(mpl.patches.Patch(facecolor=viridis_cm(i / (steps - 1))))\n",
    "\n",
    "ax1.legend(\n",
    "    [colourmap_handle, ax1.get_children()[2], ax1.get_children()[0]],\n",
    "    [\"mean\", \"variance\", \"data\"],\n",
    "    handler_map={list: HandlerTuple(None, pad=0)},\n",
    ")\n",
    "\n",
    "fig.set_size_inches(10, 10)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"longitudinal_error_rate_gp.pdf\", bbox_inches=\"tight\")\n",
    "fig.savefig(\"longitudinal_error_rate_gp.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import the data for the scale factor GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VelCurv = pd.read_csv(dependencies_folder.joinpath(\"VelCurv.csv\"))\n",
    "\n",
    "x_data = VelCurv[\"curvatures\"].to_numpy()\n",
    "y_data = VelCurv[\"long_dt_errors\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit the scale factor GP on VelCurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS: int = 500  # 2000\n",
    "INDUCING_POINTS: int = 10\n",
    "GRID_SIZE: int = 1000\n",
    "MODEL_INFO: dict[str, str] = {\"error\": \"longitudinal error rate standard deviation scale\", \"param1\": \"curvature\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the model\n",
    "\n",
    "GP_model_scale = DualGaussianProcessWrapper(\n",
    "    x_data=x_data,\n",
    "    y_data=y_data,\n",
    "    train_mask=make_train_test_split(len(y_data)),\n",
    "    no_inducing_points=INDUCING_POINTS,\n",
    "    data_directory=str(pathlib.Path().resolve()),  # current directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Going to train for {EPOCHS} epochs...\")\n",
    "GP_model_scale.train(epochs=EPOCHS)\n",
    "print(f\"Plotting the posterior...\")\n",
    "GP_model_scale.plot_posterior()\n",
    "print(f\"Generating the error model (interpolation grid)...\")\n",
    "GP_model_scale.generate_error_model(grid_size=GRID_SIZE, model_info=MODEL_INFO)\n",
    "print(f\"Saving the error model...\")\n",
    "GP_model_scale.save_error_model()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = GP_model_scale.plot_posterior(return_fig=True)\n",
    "\n",
    "ax = fig.get_axes()[0]\n",
    "\n",
    "ax.set_xlabel(\"curvature [m\" + r\"$^{-1}$\" + \"]\")\n",
    "ax.set_ylabel(\"error [m/s]\")\n",
    "ax.set_title(\"Scale function\\n\")\n",
    "ax.text(0.5, 1.03, \"of the longitudinal trajectory following error rate\", fontsize=10, ha=\"center\", transform=ax.transAxes)\n",
    "\n",
    "fig.savefig(\"longitudinal_error_rate_scale_function_gp.pdf\", bbox_inches=\"tight\")\n",
    "fig.savefig(\"longitudinal_error_rate_scale_function_gp.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Extra] Generate the error model with the scale function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_model import ErrorModelWithStdScaleFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_error_rate_std_scale_function(curvature: float) -> float:\n",
    "    \"\"\"factor = std[curvature] / std[0]\"\"\"\n",
    "    _, std0 = GP_model_scale(np.array([[0]], dtype=float)) # std at zero\n",
    "    _, std1 = GP_model_scale(np.array([[curvature]], dtype=float)) # std at the current curvature\n",
    "    return std1 / std0\n",
    "\n",
    "long_error_rate_model = ErrorModelWithStdScaleFunc.from_error_model(\n",
    "    base_model=GP_model_main.error_model,\n",
    "    std_scale_func=long_error_rate_std_scale_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get some longitudinal error rate values for a range of values \n",
    "\n",
    "accelerations = np.linspace(-0.2, 0.2, 10)\n",
    "velocities = np.linspace(0.1, 0.5, 10)\n",
    "curvature = 1  # highest value for the whole trajectory\n",
    "std_margins = 2  # amount of standard deviations wanted as a margin for the error\n",
    "\n",
    "long_error_rate_model(np.vstack((accelerations, velocities)).T, stds_margin=std_margins, curvature = curvature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
